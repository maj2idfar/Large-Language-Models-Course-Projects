{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALnEUrLq1-kp"
      },
      "source": [
        "## CA 2, LLMs Spring 2024\n",
        "\n",
        "- **Name:** Majid Faridfar\n",
        "- **Student ID:** 819199569\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfrgatGB3Aac"
      },
      "source": [
        "# What are Soft prompts?\n",
        "Soft prompts are learnable tensors concatenated with the input embeddings that can be optimized to a dataset; the downside is that they aren’t human readable because you aren’t matching these “virtual tokens” to the embeddings of a real word.\n",
        "<br>\n",
        "<div>\n",
        "<img src=\"https://www.researchgate.net/publication/366062946/figure/fig1/AS:11431281105340756@1670383256990/The-comparison-between-the-previous-T5-prompt-tuning-method-part-a-and-the-introduced.jpg\"/>\n",
        "</div>\n",
        "\n",
        "Read More:\n",
        "<br>[Youtube : PEFT and Soft Prompt](https://www.youtube.com/watch?v=8uy_WII76L0)\n",
        "<br>[Paper: The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf)\n",
        "https://arxiv.org/pdf/2101.00190.pdf\n",
        "<br>[Paper: Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLaYIRN4X7cC"
      },
      "source": [
        "# Part 1 (20 Points)\n",
        "**A) Compare and contrast model tuning and prompt tuning in terms of their effectiveness for specific downstream tasks. (5 Points)**\n",
        "\n",
        "> **Model tuning**: It involves fine-tuning the entire pre-trained language model on a downstream task-specific dataset. During fine-tuning, the model's parameters are updated across all layers based on the task data. It is generally effective for a wide range of tasks and in this way model can capture intricate task nuances as the entire model is adapted. But it requires a large amount of task-specific data to be effective and it is computationally expensive and time-consuming, especially for large models and datasets.\n",
        ">\n",
        "> **Prompt Tuning**: It involves providing task-specific prompts or instructions to guide the model's predictions without fine-tuning its parameters. Soft prompts, in particular, are used to softly constrain the model's output. This approach is effective for tasks where limited task-specific data is available. It is relatively computationally efficient compared to full model fine-tuning, and also doing it is possible when the model is not available (e.g. GPT-4). On the other hand, it may not be as effective for complex tasks that require deep understanding or extensive context. It requires careful design of prompts, which might be challenging for some tasks and performance heavily relies on the quality and relevance of the prompts provided. The other challenge is the length of the prompt which is limited.\n",
        "\n",
        "**B) Explore the challenges associated with interpreting soft prompts in the continuous embedding space and propose potential solutions. (5 Points)**\n",
        "\n",
        "> 1. The lack of direct correspondence between continuous embeddings and human-interpretable concepts is the most important challenge. Unlike discrete tokens or words, which have clear meanings, embeddings represent abstract numerical vectors in a high-dimensional space, making their interpretation non-trivial. Additionally, soft prompts may contain nuanced or ambiguous language, further complicating their interpretation.\n",
        ">   - *Solution*: Incorporating interpretability techniques that map the continuous embedding space to more interpretable representations. For example, dimensionality reduction techniques such as `Principal Component Analysis (PCA)` or `t-SNE` can be applied to visualize embeddings in lower-dimensional spaces, allowing for easier interpretation and analysis. Additionally, methods like `saliency mapping` or `attention visualization` can highlight the parts of the input or context that the model focuses on when generating outputs based on soft prompts, providing insights into how the prompts influence model behavior.\n",
        "> 2. Varying levels of granularity and specificity can impact the effectiveness of soft prompts. For instance, a prompt that is too general or vague may not provide sufficient guidance to the model, leading to ambiguous or irrelevant outputs. Conversely, a prompt that is overly specific may restrict the model's flexibility and hinder its ability to generate diverse or creative responses. Thus, finding the right balance in the granularity and specificity of soft prompts is crucial to ensure they effectively guide the model while allowing for flexibility and creativity in generating outputs.\n",
        ">   - *Solution*: standardizing the construction of soft prompts and providing guidelines for their formulation can help ensure consistent granularity and specificity across prompts. Moreover, incorporating domain-specific knowledge or leveraging pre-trained embeddings tailored to the task domain can enhance the relevance and effectiveness of soft prompts.\n",
        "> 3. Soft prompts may suffer from noise or redundancy, which can diminish their interpretability and effectiveness. Noise refers to irrelevant or distracting information in the prompt that does not contribute to guiding the model effectively. Redundancy, on the other hand, involves the repetition of similar information within the prompt, leading to inefficiencies in model learning and potentially biasing the generated outputs. Addressing noise and redundancy in soft prompts is essential to enhance their clarity and relevance, thereby improving the interpretability and effectiveness of the prompts in guiding the model's behavior accurately towards desired outputs.\n",
        ">   - *Solution*: Techniques such as filtering out irrelevant words or phrases, applying regularization methods during training to encourage the model to focus on relevant prompt information, and incorporating attention mechanisms to dynamically weigh the importance of different parts of the prompt can help reduce noise and improve the relevance of soft prompts.\n",
        "\n",
        "**C) What is the effect of initializing prompts randomly versus initializing them from the vocabulary, and how does this impact the performance of prompt tuning? (5 Points)**\n",
        "\n",
        ">  When prompts are initialized randomly, they lack any inherent semantic meaning or relevance to the task. As a result, the model may struggle to effectively utilize these prompts to guide its predictions, but it can be also effective, because of the diversity among prompts, as each prompt starts from a different point in the embedding space. But generally speaking, they are less likely to provide useful guidance to the model, leading to suboptimal performance. The model may fail to capture relevant task-specific information, resulting in lower accuracy and generalization performance. Also randomly initialized prompts may require more fine-tuning steps to converge to effective representations and the resulting embeddings may not align well with the downstream task.\n",
        ">\n",
        "> On the other hand, Initializing prompts from the vocabulary involves selecting words or phrases from the model's vocabulary that are semantically related to the task. These prompts are more likely to provide relevant guidance to the model. They are more effective in guiding the model's predictions, as they contain semantically meaningful information related to the task. This can lead to improved performance in terms of accuracy, generalization, and task-specific metrics. Also they require fewer fine-tuning steps to adapt to the task-specific context.\n",
        "\n",
        "**D) How is the optimization process in the prefix tuning(<br>[Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf)) and Why did they use this technique? (5 Points)**\n",
        "\n",
        "> The key idea which is provided is that instead of fine-tuning the entire model, prefix tuning optimizes and tuning some small continuous vector (the prefix) added to each transformer block (i.e. layer) while keeping the original language model parameters frozen. In the following, a list of the reasons why they use it, is provided:\n",
        ">\n",
        "> - **Space Efficiency**: Only the prefixes need to be stored for each task, making it modular and memory-efficient.\n",
        ">\n",
        "> - **Low Parameter Update**: Learning only a small fraction of the parameters (0.1%) achieves comparable performance.\n",
        ">\n",
        "> - **Generalization**: Prefix tuning extrapolates better to examples with unseen topics during training.\n",
        ">\n",
        "> - **Modularity**: Despite full fine-tuning, by just replacing prefixes, we can adopt them to a completely different task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMgi75DV-bo"
      },
      "source": [
        "# Part 2 (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3gjmZROpLP5"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZG_yY6ep9C7S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_UcfBmLpRiJ"
      },
      "source": [
        "## Model Selection & Constants\n",
        "We will use `bert-fa-base-uncased` as our base model from Hugging Face ([HF_Link](https://huggingface.co/HooshvareLab/bert-fa-base-uncased)). For our tuning, we intend to utilize 20 soft prompt tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mV2aP8bwV-z5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "625ca8e237f44a2083336a9e8ff13010",
            "ed19b35ed06a4218a23e74aa0eb85146",
            "071875e30a084ed8a6e5bde8e4cc191e",
            "79d7b553d29547e88d6b31cded02159a",
            "196e88a6ba9f4ef5af0994ac4e3293eb",
            "b455c032293a40f690bec5b1fc32840d",
            "922c20220b524c92ba83b2c2edbda6fe",
            "131804f297b8488392f76b07891a0023",
            "a8b1bda76e2146ddbffc94b57e1f574f",
            "3a6c1ae35d2a4960a75a241bd62a4052",
            "75bcb89815bf4d49a7cd675cf6750ece",
            "3aa459dfdd8f4391bce6df5beef8f5f9",
            "db5cbaa70728499fbdd4711fe2d023cd",
            "9d0ec210a6864efda03462c036b66669",
            "47da836e10e8475a9f212d3723b9dc24",
            "12360034ef8b44e5b88598145fcc9fbc",
            "233a10484c5c47028e8e4c09c15e1903",
            "bc94371e9c79445dbb4eeda1d0859149",
            "a208288a06e34dbbb8707aa22c9dd7d2",
            "be9a8407e6d54d99bdf627d1e2df3da4",
            "0538ad9706ed4caebcf221ab444dda19",
            "0d05bcdcc06848ff92e812aee097fe25"
          ]
        },
        "outputId": "9a4a57b7-5f1c-417a-d567-17a7eaa03948"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "625ca8e237f44a2083336a9e8ff13010"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3aa459dfdd8f4391bce6df5beef8f5f9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "class CONFIG:\n",
        "    seed = 42\n",
        "    max_len = 128\n",
        "    train_batch = 16\n",
        "    valid_batch = 32\n",
        "    epochs = 10\n",
        "    n_tokens=20\n",
        "    learning_rate = 0.01\n",
        "    model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T0asPslpkSh"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset contains around 7000 Persian sentences and their corresponding polarity, and have been manually classified into 5 categories (i.e. Angry)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpsgvYumvNa"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz63BX8ynALR",
        "outputId": "c02b6881-6afb-42f6-dd48-13c564dad3c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b2JmHJ2wpoaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = \"drive/MyDrive/LLM/CA2/softprompt_dataset.csv\"\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmviyjCrz6mi"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PITqCGDx0McE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e60f9af-26a1-4160-ca93-d6a7b1042d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clean-text[gpl]\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text[gpl])\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text[gpl])\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode<2.0.0,>=1.1.1 (from clean-text[gpl])\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text[gpl]) (0.2.13)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171034 sha256=56660c22d94d6a1c0a1c2011eecec888d47604df53c70d048eb51e15d62b4cda\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, unidecode, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.2.0 unidecode-1.3.8\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flashtext<3.0,>=2.7 (from hazm)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.2)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Collecting numpy==1.24.3 (from hazm)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm)\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.4.0)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=9ea173c75b620c79549b4d192276d2e52693530cb012e2c41926e296179eb75d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: python-crfsuite, flashtext, pybind11, numpy, fasttext-wheel, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.10.0 numpy-1.24.3 pybind11-2.12.0 python-crfsuite-0.9.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "5085183fdfc44cc6a4ec74e6eccce62d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install -U clean-text[gpl]\n",
        "%pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U0Nlfm0qE_1P"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from cleantext import clean\n",
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k4CFqPaV0Pqp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    text = cleanhtml(text)\n",
        "\n",
        "    # normalizing\n",
        "    # normalizer = hazm.Normalizer()\n",
        "    # text = normalizer.normalize(text)\n",
        "\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "\n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z_5ZyotA0cxw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def parallel_apply_with_progress(df, func, n_workers=4):\n",
        "    with ThreadPoolExecutor(max_workers=n_workers) as executor, tqdm(total=len(df)) as pbar:\n",
        "        def update(*args):\n",
        "            pbar.update()\n",
        "\n",
        "        results = []\n",
        "        for result in executor.map(func, df['text']):\n",
        "            results.append(result)\n",
        "            update()\n",
        "\n",
        "        df['text'] = pd.Series(results)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APUjLG3E0qxK",
        "outputId": "38a4240f-1cae-4df5-d6c1-d773365020bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7023/7023 [00:04<00:00, 1448.35it/s]\n"
          ]
        }
      ],
      "source": [
        "df = parallel_apply_with_progress(df, cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_2tZk2fBSwJL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "train_df = df.loc[X_train]\n",
        "validation_df = df.loc[X_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GTgl8-RV926",
        "outputId": "fa35a367-5a61-4cea-b985-25709f9a2144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, -1: 3, -2: 4}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "possible_labels = df.label.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IgTnO4ctWKqo"
      },
      "outputs": [],
      "source": [
        "train_df['label'] = train_df.label.replace(label_dict)\n",
        "validation_df['label'] = validation_df.label.replace(label_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqIWHJ9XMiOr"
      },
      "source": [
        "### Create Dataset Class (5 Points)\n",
        "In this step we will getting our dataset ready for training.\n",
        "\n",
        "In this part we will define BERT-based dataset class for text classification, with configuration parameters. It preprocesses text data and tokenizes it using the BERT tokenizer.\n",
        "\n",
        "\n",
        "Complete the preprocessing step in the __getitem__ method by adding padding tokens to 'input_ids' and 'attention_mask',\n",
        "The count of this pad tokens is the same as `n_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CyS6DyeZ75bZ"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self,df):\n",
        "        self.text = df['text'].values\n",
        "        self.labels = df['label'].values\n",
        "        self.all_labels = [0, 1, 2, 3, 4]\n",
        "        self.max_len = CONFIG.max_len\n",
        "        self.tokenizer = CONFIG.tokenizer\n",
        "        self.n_tokens=CONFIG.n_tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.text[index]\n",
        "        text = ' '.join(text.split())\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ######### Your code begins #########\n",
        "        inputs['input_ids'] = torch.tensor(inputs['input_ids'] + [self.tokenizer.pad_token_id]*self.n_tokens, dtype=torch.long)\n",
        "        inputs['attention_mask'] = torch.tensor(inputs['attention_mask'] + [0]*self.n_tokens, dtype=torch.long)\n",
        "        ######### Your code ends ###########\n",
        "\n",
        "        labels = self.labels[index]\n",
        "        label_dict = {label: (label == labels) for label in self.all_labels}\n",
        "        labels_tensor = torch.tensor([float(label_dict[label]) for label in self.all_labels])\n",
        "        return {\n",
        "            'ids': inputs['input_ids'],\n",
        "            'mask': inputs['attention_mask'],\n",
        "            'label': labels_tensor\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qf8AYo8cFiud"
      },
      "outputs": [],
      "source": [
        "train_dataset = BERTDataset(train_df)\n",
        "validation_dataset = BERTDataset(validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSWkTORNcxvx"
      },
      "source": [
        "## Define Prompt Embedding Layer (15 Points)\n",
        "In this part we will define our prompt layer in `PROMPTEmbedding` module.\n",
        "\n",
        "\n",
        "<font color='#73FF73'><b>You have to complete</b></font> `initialize_embedding` and  `forward` <font color='#73FF73'><b>functions.</b></font>\n",
        "\n",
        "In `initialize_embedding` function initialize the learned embeddings based on whether they should be initialized from the vocabulary or randomly within the specified range.\n",
        "\n",
        "In `forward` function, modify the input_embedding to extract the relevant part based on n_tokens.\n",
        "\n",
        "Repeat the learned_embedding to match the size of input_embedding.\n",
        "\n",
        "Concatenate the learned_embedding and input_embedding properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tqAU4Ubj2t8"
      },
      "outputs": [],
      "source": [
        "class PROMPTEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                emb_layer: nn.Embedding,\n",
        "                n_tokens: int = 20,\n",
        "                random_range: float = 0.5,\n",
        "                initialize_from_vocab: bool = True):\n",
        "\n",
        "      super(PROMPTEmbedding, self).__init__()\n",
        "      self.emb_layer = emb_layer\n",
        "      self.n_tokens = n_tokens\n",
        "      self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(emb_layer,\n",
        "                                                                               n_tokens,\n",
        "                                                                               random_range,\n",
        "                                                                               initialize_from_vocab))\n",
        "\n",
        "    def initialize_embedding(self,\n",
        "                             emb_layer: nn.Embedding,\n",
        "                             n_tokens: int = 20,\n",
        "                             random_range: float = 0.5,\n",
        "                             initialize_from_vocab: bool = True):\n",
        "\n",
        "      if initialize_from_vocab:\n",
        "        ######### Your code begins #########\n",
        "        vocab_emb = self.emb_layer.weight[:n_tokens].clone().detach()\n",
        "\n",
        "        return vocab_emb\n",
        "\n",
        "      else:\n",
        "        # random_emb =\n",
        "        random_emb = torch.FloatTensor(n_tokens, emb_layer.weight.size(1)).uniform_(-random_range, random_range)\n",
        "        ######### Your code ends ###########\n",
        "      return random_emb\n",
        "\n",
        "\n",
        "    def forward(self, tokens):\n",
        "      ######### Your code begins #########\n",
        "      input_embedding = self.emb_layer(tokens[:, self.n_tokens:])\n",
        "      learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n",
        "      joined_embedding = torch.cat([learned_embedding, input_embedding], dim=1)\n",
        "      ######### Your code ends ###########\n",
        "      return joined_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhES_23bDfXZ"
      },
      "source": [
        "## Replace model's embedding layer with our layer (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AMhjuooOQKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "5f876192593e45ecbf7f2996fbdc47fb",
            "ada58684514e4c15ab32bce40be0de7c",
            "6e3c70efed8246d996343c1474f6ec99",
            "010a37efcaaa41b383920ea3192c7f1e",
            "32b37d2ab9494263afee2e4e54c90d64",
            "d32a793f72954d6ba4f00b75cb459213",
            "215c135b46754b338b2e3a1154eb5448",
            "4eecd456b8d24aa79e85766b18e95d9b",
            "6e8db39391c84ffba8ee270371b5948d",
            "e93fd943932c46178154f511ff0d9a19",
            "511b158fa754410289127f4620755d0a"
          ]
        },
        "outputId": "cedfd7d0-7ffb-440b-bc38-a0a8d171bf84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f876192593e45ecbf7f2996fbdc47fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define your BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                           output_hidden_states = False).to(CONFIG.device)\n",
        "######### Your code begins #########\n",
        "model.set_input_embeddings(PROMPTEmbedding(model.get_input_embeddings(), n_tokens=20, initialize_from_vocab=True).to(CONFIG.device))\n",
        "######### Your code ends ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wlsc2meajrn"
      },
      "source": [
        "## Freezing Model Parameters (5 points)\n",
        "In this part we will freeze entire model except `learned_embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CCq8Z1lajGC"
      },
      "outputs": [],
      "source": [
        "######### Your code begins #########\n",
        "for name, param in model.named_parameters():\n",
        "    if 'learned_embedding' not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "for param in model.get_input_embeddings().parameters():\n",
        "    param.requires_grad = True\n",
        "######### Your code ends ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8ud-O_Rrptq"
      },
      "source": [
        "## Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IckuDmDWRye"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17S9KFKM1jgP"
      },
      "source": [
        "## Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZsfsyKAY2yu"
      },
      "source": [
        "### Define dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mVRa2SLDWUM9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=CONFIG.valid_batch,\n",
        "                              num_workers=2, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Sj5pT6ZDbz"
      },
      "source": [
        "### Define evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3f-OVsQ5_War"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = np.argmax(labels, axis=1).flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-bqs9Hxi9yjz"
      },
      "outputs": [],
      "source": [
        "def evaluate(val_dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "        logits = outputs[\"logits\"]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(val_dataloader)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjO1TwDSZMWH"
      },
      "source": [
        "### Define trainng loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xjXZ7oB_1jGv"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_dataloader, val_dataloader):\n",
        "\n",
        "    epochs = CONFIG.epochs\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      loss_train_total = 0\n",
        "\n",
        "      progress_bar = tqdm(train_loader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=True)\n",
        "\n",
        "      for batch in progress_bar:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = {'input_ids':      batch['ids'].to(CONFIG.device),\n",
        "                  'attention_mask': batch['mask'].to(CONFIG.device),\n",
        "                  'labels':         batch['label'].to(CONFIG.device),\n",
        "                }\n",
        "\n",
        "        output = model(**inputs)\n",
        "\n",
        "        loss = output[\"loss\"]\n",
        "        loss_train_total += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "      tqdm.write(f'\\nEpoch {epoch}')\n",
        "      loss_train_avg = loss_train_total/len(train_loader)\n",
        "      tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "\n",
        "      val_loss, predictions, true_vals = evaluate(val_dataloader)\n",
        "      val_f1 = f1_score_func(predictions, true_vals)\n",
        "      tqdm.write(f'Validation loss: {val_loss}')\n",
        "      tqdm.write(f'F1 Score (Weighted): {val_f1}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaTI1yeyZW1i"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--yqi1tp1jCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ce112a-03c6-4eea-9acf-d1d5b73f4555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [01:55<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.46414429180443606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [02:06<18:58, 126.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.44740983121322864\n",
            "F1 Score (Weighted): 0.33053933691732373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [04:04<18:58, 126.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.4406909834254872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [04:15<17:03, 127.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.43827955650560785\n",
            "F1 Score (Weighted): 0.3511486082747115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [06:13<17:03, 127.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.422047401972633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [06:24<14:58, 128.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4315464361147447\n",
            "F1 Score (Weighted): 0.3954197636354205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [08:22<14:58, 128.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.40422259446452646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [08:33<12:52, 128.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4334870901974765\n",
            "F1 Score (Weighted): 0.3812497371749612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [10:31<12:52, 128.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.3919458670571526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [10:42<10:44, 128.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.43270766102906427\n",
            "F1 Score (Weighted): 0.39798606056613095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [12:40<10:44, 128.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.38016493857544376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [12:51<08:35, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.445610346216144\n",
            "F1 Score (Weighted): 0.35273101369667165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [14:49<08:35, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.3721821090196543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:59<06:26, 128.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.43875800479542126\n",
            "F1 Score (Weighted): 0.39046256228350473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [16:58<06:26, 128.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.3634722029620951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [17:08<04:17, 128.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4399853285514947\n",
            "F1 Score (Weighted): 0.39234451106361284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [19:06<04:17, 128.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.3594559298798362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [19:17<02:08, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4448000192642212\n",
            "F1 Score (Weighted): 0.3923359444669264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [21:15<02:08, 128.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.3542546399216601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [21:26<00:00, 128.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4439676647836512\n",
            "F1 Score (Weighted): 0.392965352709498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model=model, optimizer=optimizer, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_3FYFfIUKeE"
      },
      "source": [
        "## Using OpenDelta library (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yp3_9J0wUBxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015fa225-a082-4041-f5c7-3429d0c3d8bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.2/623.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for opendelta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for web.py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip install opendelta\n",
        "!pip install git+https://github.com/thunlp/OpenDelta.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pOwAdIRUIKh"
      },
      "source": [
        "Use `OpenDelta` library to do the same thing. [link](https://opendelta.readthedocs.io/en/latest/modules/deltas.html)\n",
        "\n",
        "For hyperparameters, test with `N_SOFT_PROMPT_TOKENS=10` and `N_SOFT_PROMPT_TOKENS=20` and report them."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N_SOFT_PROMPT_TOKENS=$10$"
      ],
      "metadata": {
        "id": "MWqWs8CxFMGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LiNnIlRlUFyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36ea354-2878-4088-f0bf-242524de44fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "######### Your code begins #########\n",
        "model_10 = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                              output_hidden_states = False)\n",
        "\n",
        "from opendelta.delta_models.soft_prompt import SoftPromptModel\n",
        "\n",
        "soft_prompt_model_10 = SoftPromptModel(backbone_model=model_10, soft_token_num=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_10.named_parameters():\n",
        "    if 'soft' not in name:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True"
      ],
      "metadata": {
        "id": "JvOuwT5JEnQt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "model = model_10.to(CONFIG.device)\n",
        "optimizer_10 = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ],
      "metadata": {
        "id": "2jHTZ-8zKcet"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model=model, optimizer=optimizer_10, train_dataloader=train_loader, val_dataloader=validation_loader)"
      ],
      "metadata": {
        "id": "gt_irfyHEhfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7696dbed-bd3c-4616-aecd-d4b92d1ce1f5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [01:41<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.4660185673498215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [01:50<16:38, 110.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.44935640692710876\n",
            "F1 Score (Weighted): 0.2579362611466247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [03:32<16:38, 110.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.45016806449163405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [03:41<14:45, 110.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.42353456580277643\n",
            "F1 Score (Weighted): 0.4128747167666182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [05:23<14:45, 110.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4387865806805259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [05:33<12:59, 111.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4118667859019655\n",
            "F1 Score (Weighted): 0.3864357699433583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3/10 [07:15<12:59, 111.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.4289764070255871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [07:24<11:08, 111.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.4137817241928794\n",
            "F1 Score (Weighted): 0.3650270739911692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4/10 [09:07<11:08, 111.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.4256678369434122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [09:16<09:17, 111.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.40112626462271717\n",
            "F1 Score (Weighted): 0.41127499458424965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [10:58<09:17, 111.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.4198895745417651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [11:08<07:25, 111.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39659980752251367\n",
            "F1 Score (Weighted): 0.4286962704813638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6/10 [12:50<07:25, 111.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.415539147382114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [12:59<05:34, 111.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3989231568394285\n",
            "F1 Score (Weighted): 0.4135581317129942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7/10 [14:40<05:34, 111.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.41356448725583084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [14:49<03:42, 111.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3961534590432138\n",
            "F1 Score (Weighted): 0.40244766402375404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [16:30<03:42, 111.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.4130800328949556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [16:40<01:50, 110.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.39264370184956177\n",
            "F1 Score (Weighted): 0.41737811619142146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [18:21<01:50, 110.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.41120904070489545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [18:31<00:00, 111.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.389098657803102\n",
            "F1 Score (Weighted): 0.4718776819375309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N_SOFT_PROMPT_TOKENS=$20$"
      ],
      "metadata": {
        "id": "ca-9VJ_2FUgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_20 = AutoModelForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=5, output_attentions = False,\n",
        "                                                              output_hidden_states = False)\n",
        "\n",
        "from opendelta.delta_models.soft_prompt import SoftPromptModel\n",
        "\n",
        "soft_prompt_model_20 = SoftPromptModel(backbone_model=model_20, soft_token_num=20)"
      ],
      "metadata": {
        "id": "HXjqD8_AEh0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af276b2a-b21f-43db-89cb-ecc1f52426ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model_20.named_parameters():\n",
        "    if 'soft' not in name:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True"
      ],
      "metadata": {
        "id": "AYJtkTorE5Ue"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "model = model_20.to(CONFIG.device)\n",
        "optimizer_20 = AdamW(model.parameters(), lr=CONFIG.learning_rate)"
      ],
      "metadata": {
        "id": "FA0ZFgd6Kity"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model=model, optimizer=optimizer_20, train_dataloader=train_loader, val_dataloader=validation_loader)\n",
        "######### Your code ends ###########"
      ],
      "metadata": {
        "id": "PEUtXFAzFASU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ab5674-0f01-41f9-d007-2aedfd72dc8e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [01:52<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "Training loss: 0.47246310680626546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [02:02<18:26, 122.89s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.46072265686410846\n",
            "F1 Score (Weighted): 0.13008501385989663\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [03:56<18:26, 122.89s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2\n",
            "Training loss: 0.45844229896438315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [04:06<16:25, 123.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4437518164967046\n",
            "F1 Score (Weighted): 0.3716893018005042\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [05:59<16:25, 123.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3\n",
            "Training loss: 0.4399613937273382\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [06:09<14:23, 123.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.41151720104795514\n",
            "F1 Score (Weighted): 0.3992837151417445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [08:02<14:23, 123.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4\n",
            "Training loss: 0.4257296452069665\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [08:12<12:19, 123.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.4036531484488285\n",
            "F1 Score (Weighted): 0.46779268767849197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [10:05<12:19, 123.28s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5\n",
            "Training loss: 0.41976351159460407\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [10:16<10:16, 123.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39584834828521265\n",
            "F1 Score (Weighted): 0.45756146675578063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [12:08<10:16, 123.21s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6\n",
            "Training loss: 0.4153782092632457\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [12:19<08:12, 123.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.39861914334875165\n",
            "F1 Score (Weighted): 0.45901668602005496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [14:11<08:12, 123.13s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7\n",
            "Training loss: 0.41122936158575474\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [14:21<06:08, 122.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3970255373102246\n",
            "F1 Score (Weighted): 0.43542123505220437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [16:14<06:08, 122.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8\n",
            "Training loss: 0.41085289992431906\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [16:24<04:05, 122.97s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.3919090746027051\n",
            "F1 Score (Weighted): 0.44359009236813446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8/10 [18:17<04:05, 122.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "Training loss: 0.4067633489077104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [18:27<02:03, 123.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.38809269124811346\n",
            "F1 Score (Weighted): 0.4765253721610457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9/10 [20:20<02:03, 123.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "Training loss: 0.40440401793482467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [20:31<00:00, 123.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.3879411681131883\n",
            "F1 Score (Weighted): 0.5245259005569205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f876192593e45ecbf7f2996fbdc47fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ada58684514e4c15ab32bce40be0de7c",
              "IPY_MODEL_6e3c70efed8246d996343c1474f6ec99",
              "IPY_MODEL_010a37efcaaa41b383920ea3192c7f1e"
            ],
            "layout": "IPY_MODEL_32b37d2ab9494263afee2e4e54c90d64"
          }
        },
        "ada58684514e4c15ab32bce40be0de7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32a793f72954d6ba4f00b75cb459213",
            "placeholder": "​",
            "style": "IPY_MODEL_215c135b46754b338b2e3a1154eb5448",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6e3c70efed8246d996343c1474f6ec99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eecd456b8d24aa79e85766b18e95d9b",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e8db39391c84ffba8ee270371b5948d",
            "value": 654226731
          }
        },
        "010a37efcaaa41b383920ea3192c7f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93fd943932c46178154f511ff0d9a19",
            "placeholder": "​",
            "style": "IPY_MODEL_511b158fa754410289127f4620755d0a",
            "value": " 654M/654M [00:04&lt;00:00, 184MB/s]"
          }
        },
        "32b37d2ab9494263afee2e4e54c90d64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32a793f72954d6ba4f00b75cb459213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215c135b46754b338b2e3a1154eb5448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eecd456b8d24aa79e85766b18e95d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8db39391c84ffba8ee270371b5948d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e93fd943932c46178154f511ff0d9a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511b158fa754410289127f4620755d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "625ca8e237f44a2083336a9e8ff13010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed19b35ed06a4218a23e74aa0eb85146",
              "IPY_MODEL_071875e30a084ed8a6e5bde8e4cc191e",
              "IPY_MODEL_79d7b553d29547e88d6b31cded02159a"
            ],
            "layout": "IPY_MODEL_196e88a6ba9f4ef5af0994ac4e3293eb"
          }
        },
        "ed19b35ed06a4218a23e74aa0eb85146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b455c032293a40f690bec5b1fc32840d",
            "placeholder": "​",
            "style": "IPY_MODEL_922c20220b524c92ba83b2c2edbda6fe",
            "value": "config.json: 100%"
          }
        },
        "071875e30a084ed8a6e5bde8e4cc191e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131804f297b8488392f76b07891a0023",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8b1bda76e2146ddbffc94b57e1f574f",
            "value": 440
          }
        },
        "79d7b553d29547e88d6b31cded02159a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6c1ae35d2a4960a75a241bd62a4052",
            "placeholder": "​",
            "style": "IPY_MODEL_75bcb89815bf4d49a7cd675cf6750ece",
            "value": " 440/440 [00:00&lt;00:00, 25.3kB/s]"
          }
        },
        "196e88a6ba9f4ef5af0994ac4e3293eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b455c032293a40f690bec5b1fc32840d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922c20220b524c92ba83b2c2edbda6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "131804f297b8488392f76b07891a0023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b1bda76e2146ddbffc94b57e1f574f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a6c1ae35d2a4960a75a241bd62a4052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bcb89815bf4d49a7cd675cf6750ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa459dfdd8f4391bce6df5beef8f5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db5cbaa70728499fbdd4711fe2d023cd",
              "IPY_MODEL_9d0ec210a6864efda03462c036b66669",
              "IPY_MODEL_47da836e10e8475a9f212d3723b9dc24"
            ],
            "layout": "IPY_MODEL_12360034ef8b44e5b88598145fcc9fbc"
          }
        },
        "db5cbaa70728499fbdd4711fe2d023cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_233a10484c5c47028e8e4c09c15e1903",
            "placeholder": "​",
            "style": "IPY_MODEL_bc94371e9c79445dbb4eeda1d0859149",
            "value": "vocab.txt: 100%"
          }
        },
        "9d0ec210a6864efda03462c036b66669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a208288a06e34dbbb8707aa22c9dd7d2",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be9a8407e6d54d99bdf627d1e2df3da4",
            "value": 1198122
          }
        },
        "47da836e10e8475a9f212d3723b9dc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0538ad9706ed4caebcf221ab444dda19",
            "placeholder": "​",
            "style": "IPY_MODEL_0d05bcdcc06848ff92e812aee097fe25",
            "value": " 1.20M/1.20M [00:00&lt;00:00, 4.76MB/s]"
          }
        },
        "12360034ef8b44e5b88598145fcc9fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233a10484c5c47028e8e4c09c15e1903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc94371e9c79445dbb4eeda1d0859149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a208288a06e34dbbb8707aa22c9dd7d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9a8407e6d54d99bdf627d1e2df3da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0538ad9706ed4caebcf221ab444dda19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d05bcdcc06848ff92e812aee097fe25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}